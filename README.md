```markdown
# Legal Clause Semantic Similarity (Assignment 2 â€“ Deep Learning)

This repository contains the implementation for **Assignment 2 (CS-452: Deep Learning)**, where the objective is to determine whether two legal clauses express the same meaning. Legal documents often contain semantically similar clauses written in varied forms, making semantic similarity an important task in contract analysis and legal NLP.

This project implements and compares **two baseline models trained from scratch** (no transformers used):

- **BiLSTM Siamese Network**
- **Self-Attention Encoder**

---

## ğŸ“ Dataset

Dataset used: **Legal Clause Similarity Dataset**  
**Kaggle Link:** https://www.kaggle.com/datasets/bahushruth/legalclausedataset

After downloading, extract the dataset and place it inside the project directory as:

```

dataset/
acceleration.csv
access-to-information.csv
accounting-terms.csv
...

```

Each CSV contains a set of clauses belonging to a particular legal category.

---

## ğŸ§  Problem Formulation

Given two clauses:

```

Clause A: "The parties agree to maintain confidentiality."
Clause B: "Neither party shall disclose shared information to external entities."

```

The model outputs:

```

1 â†’ Similar meaning
0 â†’ Different meaning

```

This is treated as a **binary classification** task.

---

## ğŸ› Model Architectures

| Model | Description |
|------|-------------|
| **BiLSTM Siamese Network** | Encodes each clause using Bidirectional LSTM and compares embeddings. |
| **Self-Attention Encoder** | Uses embedding + attention to highlight important legal terms and compare representations. |

---

## âš™ï¸ Training Setup

| Parameter | Value |
|----------|-------|
| Max sequence length | 40 tokens |
| Vocabulary size | 20,000 |
| Embedding size | 128 |
| Batch size | 32 |
| Optimizer | Adam (LR = 0.001) |
| Epochs | 5 |

---

## ğŸ“Š Final Results

| Model | Accuracy | Precision | Recall | F1-Score |
|------|----------|------------|--------|---------|
| **BiLSTM Siamese** | **0.7867** | 0.7593 | 0.8281 | **0.7840** |
| **Self-Attention Encoder** | **0.7814** | 0.7878 | 0.7345 | **0.7602** |

### ğŸ¯ Interpretation
- BiLSTM performs slightly better due to stronger contextual sequence understanding.
- Attention model performs well but is more sensitive to phrase ordering and long clauses.

---

## ğŸ“ˆ Training Curves (Observed Behavior)

- Training accuracy increases steadily across epochs.
- Validation accuracy stabilizes around **~0.77â€“0.79**, indicating good generalization.
- Loss decreases smoothly, with no major signs of overfitting.

---

## â–¶ï¸ How to Run

Install dependencies:

```

pip install tensorflow pandas numpy scikit-learn

```

Run training:

```

python main.py

```

If using Google Colab:

```

!pip install kaggle

```

Then download dataset and extract to `dataset/` folder.

---

## ğŸ§© Repository Structure

```

main.py                     # End-to-end training and evaluation pipeline
README.md                   # Project documentation
dataset/                    # Legal clause dataset (not included in repo upload)

```

---

## ğŸ‘¨â€ğŸ’» Author

**Name:** Amman Faisal  
---

## âœ… Submission Checklist

- [x] Data Loaded and Cleaned
- [x] Pair Generation Implemented
- [x] BiLSTM Siamese Model Trained
- [x] Attention Encoder Model Trained
- [x] Performance Metrics Compared
- [x] Ready for GitHub Upload
- [ ] Short PDF Report (Tell me when you want it â€” I will generate it)

---


**Ready when you are.** ğŸš€
```
